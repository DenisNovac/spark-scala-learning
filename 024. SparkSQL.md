# Spark SQL

Starting with Spark 2.
Modern API - Dataframes and Datasets. 
Layer on top of Spark Core (RDD).

## DataFrame

DataFrame is extension of RDD.
  
DataFrame looks more like actual DB:
  - more automatic optimizations than RDD;
  - contain Row objects;
  - can run SQL;
  - has schema (leading to efficient storage);
  - read and write to JSON, Hive, parquet...
  - commincates with JDBC, Tableau.

## DataSets

DataFrame is a DataSet of Row (`DataSet[Row]`).

DataSets can wrap a given type: `DataSet[(String, Double)]`.

**DataSet schema could be inferred at compile time (insted of runtime in DataFrame). Errors could be found before running.**

Even more optimization than DataFrame (some at compile time).

Can't be used in Python (no compile).

RDDs can be converted to DataSets with `.toDS()`.

SparkSession instead of SparkContext.

## Other features

Spark SQL exposes JDBC server (if used with Hive support);
port 10000 by default;
jdbc:hive2:localhost:10000

user-defined-function UDF:

```scala
val aquare = udf{ (x => x * x) }
```

