# Introduction to Spark

Fast and general engine for large-scale distributed data processing.

You can run a simple script (*driver program*) and Spark will determine how to distribute this work around cluster (parallelise processing).

## Spark structure

YARN - cluster manager of Hadoop.

Spark has own standalone cluster which might be used too.

Nodes - different machines in cluser: 
  - Executors - running on nodes:
    - own cache;
    - own tasks;

Spark is:
  - faster then Hadoop MapReduce;
  - DAG engine (directed acyclic graph) optimizes workflows:
    - automatically optimises workflow in scripts.

Above the Spark Core there are multiple APIs:
  - Spark Streaming (ingesting data in real-time);
  - Spark SQL (SQL-based interfaces such as dataframes);
  - MLLib (distributed machine learning);
  - GraphX (not really maintained now, computer science "graphs").

## Scala

- Spark is written in Scala;
- FP is good fit for distributed processing;
- Fast (comparing to Python).





